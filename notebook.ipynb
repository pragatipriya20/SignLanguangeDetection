{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "4"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 1. American Sign Language (ASL)\n",
    "<p>American Sign Language (ASL) is the primary language used by many deaf individuals in North America, and it is also used by hard-of-hearing and hearing individuals.  The language is as rich as spoken languages and employs signs made with the hand, along with facial gestures and bodily postures.</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_509/img/asl.png\" alt=\"american sign language\"></p>\n",
    "<p>A lot of recent progress has been made towards developing computer vision systems that translate sign language to spoken language.  This technology  often relies on complex neural network architectures that can detect subtle patterns in streaming video.  However, as a first step, towards understanding how to build a translation system, we can reduce the size of the problem by translating individual letters, instead of sentences.</p>\n",
    "<p><strong>In this notebook</strong>, we will train a convolutional neural network to classify images of American Sign Language (ASL) letters.  After loading, examining, and preprocessing the data, we will train the network and test its performance.</p>\n",
    "<p>In the code cell below, we load the training and test data. </p>\n",
    "<ul>\n",
    "<li><code>x_train</code> and <code>x_test</code> are arrays of image data with shape <code>(num_samples, 3, 50, 50)</code>, corresponding to the training and test datasets, respectively.</li>\n",
    "<li><code>y_train</code> and <code>y_test</code> are arrays of category labels with shape <code>(num_samples,)</code>, corresponding to the training and test datasets, respectively.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "4"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages and set numpy random seed\n",
    "import numpy as np\n",
    "np.random.seed(5) \n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "from datasets import sign_language\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# Load pre-shuffled training and test datasets\n",
    "(x_train, y_train), (x_test, y_test) = sign_language.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "11"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 2. Visualize the training data\n",
    "<p>Now we'll begin by creating a list of string-valued labels containing the letters that appear in the dataset.  Then, we visualize the first several images in the training data, along with their corresponding labels.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "11"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Store labels of dataset\n",
    "labels = ['A', 'B', 'C']\n",
    "\n",
    "# Print the first several training images, along with the labels\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "for i in range(36):\n",
    "    ax = fig.add_subplot(3, 12, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i]))\n",
    "    ax.set_title(\"{}\".format(labels[y_train[i]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "18"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. Examine the dataset\n",
    "<p>Let's examine how many images of each letter can be found in the dataset.</p>\n",
    "<p>Remember that dataset has already been split into training and test sets for you, where <code>x_train</code> and <code>x_test</code> contain the images, and <code>y_train</code> and <code>y_test</code> contain their corresponding labels.</p>\n",
    "<p>Each entry in <code>y_train</code> and <code>y_test</code> is one of <code>0</code>, <code>1</code>, or <code>2</code>, corresponding to the letters <code>'A'</code>, <code>'B'</code>, and <code>'C'</code>, respectively.</p>\n",
    "<p>We will use the arrays <code>y_train</code> and <code>y_test</code> to verify that both the training and test sets each have roughly equal proportions of each letter.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dc": {
     "key": "18"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "\tA: 540, B: 528, C: 532\n",
      "Test set:\n",
      "\tA: 118, B: 144, C: 138\n"
     ]
    }
   ],
   "source": [
    "# Number of A's in the training dataset\n",
    "num_A_train = sum(y_train==0)\n",
    "# Number of B's in the training dataset\n",
    "num_B_train = sum(y_train==1)\n",
    "# Number of C's in the training dataset\n",
    "num_C_train = sum(y_train==2)\n",
    "\n",
    "# Number of A's in the test dataset\n",
    "num_A_test = sum(y_test==0)\n",
    "# Number of B's in the test dataset\n",
    "num_B_test = sum(y_test==1)\n",
    "# Number of C's in the test dataset\n",
    "num_C_test = sum(y_test==2)\n",
    "\n",
    "# Print statistics about the dataset\n",
    "print(\"Training set:\")\n",
    "print(\"\\tA: {}, B: {}, C: {}\".format(num_A_train, num_B_train, num_C_train))\n",
    "print(\"Test set:\")\n",
    "print(\"\\tA: {}, B: {}, C: {}\".format(num_A_test, num_B_test, num_C_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "25"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. One-hot encode the data\n",
    "<p>Currently, our labels for each of the letters are encoded as categorical integers, where <code>'A'</code>, <code>'B'</code> and <code>'C'</code> are encoded as <code>0</code>, <code>1</code>, and <code>2</code>, respectively.  However, recall that Keras models do not accept labels in this format, and we must first one-hot encode the labels before supplying them to a Keras model.</p>\n",
    "<p>This conversion will turn the one-dimensional array of labels into a two-dimensional array.</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_509/img/onehot.png\" alt=\"one-hot encoding\"></p>\n",
    "<p>Each row in the two-dimensional array of one-hot encoded labels corresponds to a different image.  The row has a <code>1</code> in the column that corresponds to the correct label, and <code>0</code> elsewhere.  </p>\n",
    "<p>For instance, </p>\n",
    "<ul>\n",
    "<li><code>0</code> is encoded as <code>[1, 0, 0]</code>, </li>\n",
    "<li><code>1</code> is encoded as <code>[0, 1, 0]</code>, and </li>\n",
    "<li><code>2</code> is encoded as <code>[0, 0, 1]</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dc": {
     "key": "25"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# One-hot encode the training labels\n",
    "y_train_OH = np_utils.to_categorical(y_train)\n",
    "\n",
    "# One-hot encode the test labels\n",
    "y_test_OH = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "32"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. Define the model\n",
    "<p>Now it's time to define a convolutional neural network to classify the data.</p>\n",
    "<p>This network accepts an image of an American Sign Language letter as input.  The output layer returns the network's predicted probabilities that the image belongs in each category.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dc": {
     "key": "32"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 50, 50, 5)         380       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 5)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 15)        1890      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 3, 3, 15)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 135)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 408       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,678\n",
      "Trainable params: 2,678\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# First convolutional layer accepts image input\n",
    "model.add(Conv2D(filters=5, kernel_size=5, padding='same', activation='relu', \n",
    "                        input_shape=(50, 50, 3)))\n",
    "# Add a max pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (4,4)))\n",
    "# Add a convolutional layer\n",
    "model.add(Conv2D(filters=15, kernel_size=5, padding='same', activation='relu'))\n",
    "# Add another max pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (4,4)))\n",
    "# Flatten and feed to output layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "39"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Compile the model\n",
    "<p>After we have defined a neural network in Keras, the next step is to compile it! </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dc": {
     "key": "39"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "46"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 7. Train the model\n",
    "<p>Once we have compiled the model, we're ready to fit it to the training data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dc": {
     "key": "46"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 03:38:43.583803: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 22ms/step - loss: 0.9832 - accuracy: 0.5317 - val_loss: 0.8450 - val_accuracy: 0.7214\n",
      "Epoch 2/2\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.7675 - accuracy: 0.6904 - val_loss: 0.6614 - val_accuracy: 0.7071\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "hist = model.fit(x_train, y_train_OH, epochs=2, validation_split = 0.35, batch_size =32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "53"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 8. Test the model\n",
    "<p>To evaluate the model, we'll use the test dataset.  This will tell us how the network performs when classifying images it has never seen before!</p>\n",
    "<p>If the classification accuracy on the test dataset is similar to the training dataset, this is a good sign that the model did not overfit to the training data.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dc": {
     "key": "53"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6850000023841858\n"
     ]
    }
   ],
   "source": [
    "# Obtain accuracy on test set\n",
    "score = model.evaluate(x=x_test, \n",
    "                       y=y_test_OH,\n",
    "                       verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "61"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 9. Visualize mistakes\n",
    "<p>Hooray!  Our network gets very high accuracy on the test set!  </p>\n",
    "<p>The final step is to take a look at the images that were incorrectly classified by the model.  Do any of the mislabeled images look relatively difficult to classify, even to the human eye?  </p>\n",
    "<p>Sometimes, it's possible to review the images to discover special characteristics that are confusing to the model.  However, it is also often the case that it's hard to interpret what the model had in mind!</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dc": {
     "key": "61"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     20\u001b[0m true_label \u001b[38;5;241m=\u001b[39m labels[y_test[idx]]\n\u001b[0;32m---> 21\u001b[0m pred_label \u001b[38;5;241m=\u001b[39m labels[\u001b[43my_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     22\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (pred: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(true_label, pred_label))\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAB8AAAAfCAYAAAAfrhY5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAABxUlEQVR4nO2WzYoTQRSFv6ruTnecVMwMzibuRPAJXAkD+hqC4Nq1OzcuXfoe4iP4DO6EgATsEEYYme5O+iedzr2uMjCbSTeSycIcqF3d89W5VVSVUVXlQLKHAh/hR/gRfm/y20wSEebzOc45jDF3zlVVFosF4/EYa3dk0xaK41iBTiOO452+rZI75wD4+OkzUdSnzgu+ff3CbDrhxcUFz1+9xDOK1TXrKufd+w83NXepFXzbajc6ZdA/4fuPCfNfPxHZ8OfqitOzMZ5v8KylrqtbNf8M38oai7UeaZZQN2vCMKJeVRgMng3wfYvIpr1fF7gBEKFKEjxAmppVWYAKN0E7vJGd4JFRtC6IpxMExQD5MmddJPQCJfAUa/eUfDgwREFDtSoIfZ+wF5Kk11xfThk9CHB9w4nX3q/TnldlgWctYeCjvqVR4fz8jDDsUeYLVJU8X7T265S8qkpEBTcasqxKRsOI12/f8Gj8mCxLydKELEv3A183DarKk2dPEYR+zzJ86NhsGmTTICpdzlu7tm+/eZe/c5ZLpVxFoI5l4TGbpYQDARHAUBTlrZpdxge7Xo22WOK+HpZW8H3p//1MHOFH+L3qL7F7dqVGYwh6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predicted probabilities for test dataset\n",
    "\n",
    "y_probs = model.predict(x_test)\n",
    "\n",
    "# Get predicted labels for test dataset\n",
    "y_preds = np.argmax(600, 0)\n",
    "\n",
    "# Indices corresponding to test images which were mislabeled\n",
    "bad_test_idxs = np.where(y_test!=y_preds)\n",
    "\n",
    "# Print mislabeled examples\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for i, idx in enumerate(bad_test_idxs[0]):\n",
    "    ax = fig.add_subplot(2, int(np.ceil(len(bad_test_idxs[0])/2)), i + 1, xticks=[], yticks=[])\n",
    "    img = x_test[idx].squeeze()\n",
    "    if img.ndim == 2:\n",
    "        ax.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(img)\n",
    "    true_label = labels[y_test[idx]]\n",
    "    pred_label = labels[y_preds[idx]]\n",
    "    ax.set_title(\"{} (pred: {})\".format(true_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
